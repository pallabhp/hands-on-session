{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Training GAN"
      ],
      "metadata": {
        "id": "Ig2wvpo3fD9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#Define input image dimensions\n",
        "#Large images take too much time and resources.\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "img_shape = (img_rows, img_cols, channels)\n"
      ],
      "metadata": {
        "id": "jls2fOUumy0K"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir images"
      ],
      "metadata": {
        "id": "hv_SYktCodfA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Given input of noise (latent) vector, the Generator produces an image.\n",
        "def build_generator():\n",
        "\n",
        "    noise_shape = (100,) #1D array of size 100 (latent vector / noise)\n",
        "\n",
        "#Define your generator network \n",
        "#Here we are only using Dense layers. But network can be complicated based on the application. \n",
        "#For example, we can use VGG for super res. GAN.         \n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(256, input_shape=noise_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    \n",
        "    model.add(Dense(np.prod(img_shape), activation='tanh'))\n",
        "    model.add(Reshape(img_shape))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=noise_shape)\n",
        "    img = model(noise)    #Generated image\n",
        "\n",
        "    return Model(noise, img)\n",
        "\n",
        "#Alpha — α is a hyperparameter which controls the underlying value to which the function saturates negatives network inputs.\n",
        "#Momentum — Speed up the training"
      ],
      "metadata": {
        "id": "bIaJABHko-co"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Given an input image, the Discriminator outputs the likelihood of the image being real.\n",
        "    #Binary classification - true or false \n",
        "\n",
        "def build_discriminator():\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten(input_shape=img_shape))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=img_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)\n",
        "#The validity is the Discriminator’s guess of input being real or not.\n"
      ],
      "metadata": {
        "id": "W0I2Vk8ipGfs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(epochs, batch_size=128, save_interval=20):\n",
        "\n",
        "    # Load the dataset\n",
        "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "    # Convert to float and Rescale -1 to 1 (Can also do 0 to 1)\n",
        "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "    #Add channels dimension. As the input to our gen and discr. has a shape 28x28x1.\n",
        "    X_train = np.expand_dims(X_train, axis=3) \n",
        "\n",
        "    half_batch = int(batch_size / 2)\n",
        "\n",
        "\n",
        "#We then loop through a number of epochs to train our Discriminator by first selecting\n",
        "#a random batch of images from our true dataset, generating a set of images from our\n",
        "#Generator, feeding both set of images into our Discriminator, and finally setting the\n",
        "#loss parameters for both the real and fake images, as well as the combined loss. \n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        # Select a random half batch of real images\n",
        "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "        imgs = X_train[idx]\n",
        "\n",
        " \n",
        "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
        "\n",
        "        # Generate a half batch of fake images\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator on real and fake images, separately\n",
        "        #Research showed that separate training is more effective. \n",
        "        d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
        "    #take average loss from real and fake images. \n",
        "    #\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) \n",
        "\n",
        "#And within the same loop we train our Generator, by setting the input noise and\n",
        "#ultimately training the Generator to have the Discriminator label its samples as valid\n",
        "#by specifying the gradient loss.\n",
        "        # ---------------------\n",
        "        #  Train Generator\n",
        "        # ---------------------\n",
        "#Create noise vectors as input for generator. \n",
        "#Create as many noise vectors as defined by the batch size. \n",
        "#Based on normal distribution. Output will be of size (batch size, 100)\n",
        "        noise = np.random.normal(0, 1, (batch_size, 100)) \n",
        "\n",
        "        # The generator wants the discriminator to label the generated samples\n",
        "        # as valid (ones)\n",
        "        #This is where the genrator is trying to trick discriminator into believing\n",
        "        #the generated image is true (hence value of 1 for y)\n",
        "        valid_y = np.array([1] * batch_size) #Creates an array of all ones of size=batch size\n",
        "\n",
        "        # Generator is part of combined where it got directly linked with the discriminator\n",
        "        # Train the generator with noise as x and 1 as y. \n",
        "        # Again, 1 as the output as it is adversarial and if generator did a great\n",
        "        #job of folling the discriminator then the output would be 1 (true)\n",
        "        g_loss = combined.train_on_batch(noise, valid_y)\n",
        "\n",
        "\n",
        "#Additionally, in order for us to keep track of our training process, we print the\n",
        "#progress and save the sample image output depending on the epoch interval specified.  \n",
        "# Plot the progress\n",
        "        \n",
        "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if epoch % save_interval == 0:\n",
        "            save_imgs(epoch)\n",
        "\n",
        "#when the specific sample_interval is hit, we call the\n",
        "#sample_image function. Which looks as follows.\n",
        "\n",
        "def save_imgs(epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, 100))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
        "    plt.close()\n",
        "#This function saves our images for us to view\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AR0PRsb1fDpx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us also define our optimizer for easy use later on.\n",
        "\n",
        "optimizer = Adam(0.0002, 0.5)  #Learning rate and momentum.\n",
        "\n",
        "# Build and compile the discriminator first. \n",
        "#Generator will be trained as part of the combined model, later. \n",
        "#pick the loss function and the type of metric to keep track.                 \n",
        "#Binary cross entropy as we are doing prediction and it is a better\n",
        "#loss function compared to MSE or other. \n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "#build and compile our Discriminator, pick the loss function\n",
        "\n",
        "#SInce we are only generating (faking) images, let us not track any metrics.\n",
        "generator = build_generator()\n",
        "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "##This builds the Generator and defines the input noise. \n",
        "#In a GAN the Generator network takes noise z as an input to produce its images.  \n",
        "z = Input(shape=(100,))   #Our random input to the generator\n",
        "img = generator(z)\n",
        "\n",
        "#This ensures that when we combine our networks we only train the Generator.\n",
        "#While generator training we do not want discriminator weights to be adjusted. \n",
        "#This Doesn't affect the above descriminator training.     \n",
        "discriminator.trainable = False  \n",
        "\n",
        "#This specifies that our Discriminator will take the images generated by our Generator\n",
        "#and true dataset and set its output to a parameter called valid, which will indicate\n",
        "#whether the input is real or not.  \n",
        "valid = discriminator(img)  #Validity check on the generated image\n",
        "\n",
        "\n",
        "#Here we combined the models and also set our loss function and optimizer. \n",
        "#Again, we are only training the generator here. \n",
        "#The ultimate goal here is for the Generator to fool the Discriminator.  \n",
        "# The combined model  (stacked generator and discriminator) takes\n",
        "# noise as input => generates images => determines validity\n",
        "\n",
        "combined = Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "train(epochs=1000, batch_size=32, save_interval=50)\n",
        "\n",
        "#Save model for future use to generate fake images\n",
        "#Not tested yet... make sure right model is being saved..\n",
        "#Compare with GAN4\n",
        "\n",
        "generator.save('generator_model.h5')  #Test the model on GAN4_predict...\n",
        "#Change epochs back to 30K\n",
        "                \n",
        "#Epochs dictate the number of backward and forward propagations, the batch_size\n",
        "#indicates the number of training samples per backward/forward propagation, and the\n",
        "#sample_interval specifies after how many epochs we call our sample_image function."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyZHbzWCcZiy",
        "outputId": "92c15df1-f528-44c4-8ee8-c7221de269ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 784)               803600    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "0 [D loss: 0.730547, acc.: 50.00%] [G loss: 0.789822]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1 [D loss: 0.363203, acc.: 90.62%] [G loss: 0.791760]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2 [D loss: 0.354944, acc.: 84.38%] [G loss: 0.882730]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3 [D loss: 0.316781, acc.: 90.62%] [G loss: 0.873575]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "4 [D loss: 0.303022, acc.: 93.75%] [G loss: 0.985945]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "5 [D loss: 0.271484, acc.: 96.88%] [G loss: 1.157214]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "6 [D loss: 0.213727, acc.: 100.00%] [G loss: 1.247606]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "7 [D loss: 0.212601, acc.: 100.00%] [G loss: 1.440718]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "8 [D loss: 0.177174, acc.: 100.00%] [G loss: 1.705045]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "9 [D loss: 0.130359, acc.: 100.00%] [G loss: 1.852359]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "10 [D loss: 0.110433, acc.: 100.00%] [G loss: 1.921702]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "11 [D loss: 0.108695, acc.: 100.00%] [G loss: 2.003755]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "12 [D loss: 0.084908, acc.: 100.00%] [G loss: 2.094213]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "13 [D loss: 0.074064, acc.: 100.00%] [G loss: 2.271313]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "14 [D loss: 0.067614, acc.: 100.00%] [G loss: 2.211588]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "15 [D loss: 0.072600, acc.: 100.00%] [G loss: 2.457769]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "16 [D loss: 0.060353, acc.: 100.00%] [G loss: 2.620749]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "17 [D loss: 0.057344, acc.: 100.00%] [G loss: 2.631963]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "18 [D loss: 0.049895, acc.: 100.00%] [G loss: 2.777195]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "19 [D loss: 0.046241, acc.: 100.00%] [G loss: 2.887535]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "20 [D loss: 0.040878, acc.: 100.00%] [G loss: 2.772858]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "21 [D loss: 0.035684, acc.: 100.00%] [G loss: 2.877839]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "22 [D loss: 0.036338, acc.: 100.00%] [G loss: 2.994930]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "23 [D loss: 0.044548, acc.: 100.00%] [G loss: 3.045268]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "24 [D loss: 0.031384, acc.: 100.00%] [G loss: 2.881009]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "25 [D loss: 0.030648, acc.: 100.00%] [G loss: 3.077136]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "26 [D loss: 0.039725, acc.: 100.00%] [G loss: 3.179358]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "27 [D loss: 0.028267, acc.: 100.00%] [G loss: 3.264011]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "28 [D loss: 0.035115, acc.: 100.00%] [G loss: 3.335915]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "29 [D loss: 0.020392, acc.: 100.00%] [G loss: 3.397426]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "30 [D loss: 0.016276, acc.: 100.00%] [G loss: 3.422976]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "31 [D loss: 0.024204, acc.: 100.00%] [G loss: 3.305192]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "32 [D loss: 0.030933, acc.: 100.00%] [G loss: 3.398956]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "33 [D loss: 0.018411, acc.: 100.00%] [G loss: 3.491639]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "34 [D loss: 0.024569, acc.: 100.00%] [G loss: 3.377589]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "35 [D loss: 0.018238, acc.: 100.00%] [G loss: 3.539935]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "36 [D loss: 0.025604, acc.: 100.00%] [G loss: 3.517244]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "37 [D loss: 0.022792, acc.: 100.00%] [G loss: 3.684333]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "38 [D loss: 0.014620, acc.: 100.00%] [G loss: 3.572446]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "39 [D loss: 0.017675, acc.: 100.00%] [G loss: 3.628928]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "40 [D loss: 0.031392, acc.: 100.00%] [G loss: 3.804368]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "41 [D loss: 0.013620, acc.: 100.00%] [G loss: 3.673720]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "42 [D loss: 0.020928, acc.: 100.00%] [G loss: 3.823498]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "43 [D loss: 0.014596, acc.: 100.00%] [G loss: 3.859447]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "44 [D loss: 0.017781, acc.: 100.00%] [G loss: 3.721946]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "45 [D loss: 0.014116, acc.: 100.00%] [G loss: 3.758307]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "46 [D loss: 0.025196, acc.: 100.00%] [G loss: 3.973709]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "47 [D loss: 0.014761, acc.: 100.00%] [G loss: 3.918939]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "48 [D loss: 0.011285, acc.: 100.00%] [G loss: 3.857396]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "49 [D loss: 0.018057, acc.: 100.00%] [G loss: 3.921343]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "50 [D loss: 0.014825, acc.: 100.00%] [G loss: 3.866747]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "51 [D loss: 0.017452, acc.: 100.00%] [G loss: 3.900649]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "52 [D loss: 0.014613, acc.: 100.00%] [G loss: 3.932822]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "53 [D loss: 0.023771, acc.: 100.00%] [G loss: 3.964408]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "54 [D loss: 0.021558, acc.: 100.00%] [G loss: 4.069098]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "55 [D loss: 0.013695, acc.: 100.00%] [G loss: 4.054187]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "56 [D loss: 0.019656, acc.: 100.00%] [G loss: 4.117124]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "57 [D loss: 0.014111, acc.: 100.00%] [G loss: 4.224196]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "58 [D loss: 0.007075, acc.: 100.00%] [G loss: 4.210716]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "59 [D loss: 0.023816, acc.: 100.00%] [G loss: 4.076617]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "60 [D loss: 0.012470, acc.: 100.00%] [G loss: 3.976676]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "61 [D loss: 0.015196, acc.: 100.00%] [G loss: 4.162762]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "62 [D loss: 0.020694, acc.: 100.00%] [G loss: 4.039192]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "63 [D loss: 0.014614, acc.: 100.00%] [G loss: 3.963403]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "64 [D loss: 0.010189, acc.: 100.00%] [G loss: 4.168974]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "65 [D loss: 0.013186, acc.: 100.00%] [G loss: 4.165893]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "66 [D loss: 0.008355, acc.: 100.00%] [G loss: 4.162323]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "67 [D loss: 0.017007, acc.: 100.00%] [G loss: 4.349899]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "68 [D loss: 0.013776, acc.: 100.00%] [G loss: 4.152781]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "69 [D loss: 0.011769, acc.: 100.00%] [G loss: 4.162722]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "70 [D loss: 0.011818, acc.: 100.00%] [G loss: 4.204663]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "71 [D loss: 0.010021, acc.: 100.00%] [G loss: 4.284356]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "72 [D loss: 0.012753, acc.: 100.00%] [G loss: 4.103158]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "73 [D loss: 0.007478, acc.: 100.00%] [G loss: 4.395174]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "74 [D loss: 0.014236, acc.: 100.00%] [G loss: 4.137541]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "75 [D loss: 0.013347, acc.: 100.00%] [G loss: 4.323913]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "76 [D loss: 0.017730, acc.: 100.00%] [G loss: 4.173972]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "77 [D loss: 0.017562, acc.: 100.00%] [G loss: 4.195688]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "78 [D loss: 0.018595, acc.: 100.00%] [G loss: 4.297897]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "79 [D loss: 0.011256, acc.: 100.00%] [G loss: 4.284011]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "80 [D loss: 0.012118, acc.: 100.00%] [G loss: 4.357718]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "81 [D loss: 0.009781, acc.: 100.00%] [G loss: 4.500437]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "82 [D loss: 0.010566, acc.: 100.00%] [G loss: 4.228359]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "83 [D loss: 0.017417, acc.: 100.00%] [G loss: 4.268657]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "84 [D loss: 0.008680, acc.: 100.00%] [G loss: 4.399346]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "85 [D loss: 0.010616, acc.: 100.00%] [G loss: 4.462506]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "86 [D loss: 0.009980, acc.: 100.00%] [G loss: 4.218461]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "87 [D loss: 0.020376, acc.: 100.00%] [G loss: 4.532343]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "88 [D loss: 0.007224, acc.: 100.00%] [G loss: 4.600758]\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "89 [D loss: 0.012369, acc.: 100.00%] [G loss: 4.510067]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "90 [D loss: 0.019451, acc.: 100.00%] [G loss: 4.479521]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "91 [D loss: 0.006629, acc.: 100.00%] [G loss: 4.410650]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "92 [D loss: 0.015999, acc.: 100.00%] [G loss: 4.425619]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "93 [D loss: 0.009947, acc.: 100.00%] [G loss: 4.578238]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "94 [D loss: 0.013428, acc.: 100.00%] [G loss: 4.611635]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "95 [D loss: 0.008938, acc.: 100.00%] [G loss: 4.561610]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "96 [D loss: 0.008557, acc.: 100.00%] [G loss: 4.475931]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "97 [D loss: 0.011440, acc.: 100.00%] [G loss: 4.374012]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "98 [D loss: 0.037855, acc.: 100.00%] [G loss: 4.833890]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "99 [D loss: 0.017206, acc.: 100.00%] [G loss: 4.927662]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "100 [D loss: 0.013126, acc.: 100.00%] [G loss: 4.687685]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "101 [D loss: 0.010037, acc.: 100.00%] [G loss: 4.684318]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "102 [D loss: 0.005459, acc.: 100.00%] [G loss: 4.572256]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "103 [D loss: 0.011735, acc.: 100.00%] [G loss: 4.532003]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "104 [D loss: 0.014420, acc.: 100.00%] [G loss: 4.620894]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "105 [D loss: 0.027038, acc.: 100.00%] [G loss: 4.997314]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "106 [D loss: 0.012792, acc.: 100.00%] [G loss: 5.002434]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "107 [D loss: 0.013958, acc.: 100.00%] [G loss: 4.226929]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "108 [D loss: 0.012459, acc.: 100.00%] [G loss: 4.568885]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "109 [D loss: 0.005596, acc.: 100.00%] [G loss: 4.311190]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "110 [D loss: 0.019761, acc.: 100.00%] [G loss: 4.592348]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "111 [D loss: 0.007997, acc.: 100.00%] [G loss: 4.699149]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "112 [D loss: 0.009894, acc.: 100.00%] [G loss: 4.577188]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "113 [D loss: 0.019834, acc.: 100.00%] [G loss: 4.852532]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "114 [D loss: 0.008594, acc.: 100.00%] [G loss: 4.801350]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "115 [D loss: 0.028357, acc.: 100.00%] [G loss: 4.755091]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "116 [D loss: 0.015144, acc.: 100.00%] [G loss: 4.420889]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "117 [D loss: 0.015226, acc.: 100.00%] [G loss: 4.435930]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "118 [D loss: 0.011944, acc.: 100.00%] [G loss: 4.559510]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "119 [D loss: 0.025526, acc.: 100.00%] [G loss: 4.976991]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "120 [D loss: 0.024122, acc.: 100.00%] [G loss: 4.704774]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "121 [D loss: 0.027114, acc.: 100.00%] [G loss: 5.009176]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "122 [D loss: 0.035795, acc.: 100.00%] [G loss: 4.439054]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "123 [D loss: 0.028059, acc.: 100.00%] [G loss: 5.325910]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "124 [D loss: 0.086424, acc.: 96.88%] [G loss: 5.385694]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "125 [D loss: 0.130433, acc.: 93.75%] [G loss: 4.803204]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "126 [D loss: 0.017649, acc.: 100.00%] [G loss: 4.820955]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "127 [D loss: 0.438627, acc.: 87.50%] [G loss: 4.129596]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "128 [D loss: 0.026517, acc.: 100.00%] [G loss: 5.350015]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "129 [D loss: 0.031252, acc.: 100.00%] [G loss: 4.733295]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "130 [D loss: 0.100988, acc.: 96.88%] [G loss: 5.229450]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "131 [D loss: 0.064624, acc.: 100.00%] [G loss: 5.004847]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "132 [D loss: 0.056093, acc.: 100.00%] [G loss: 4.554867]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "133 [D loss: 0.271133, acc.: 90.62%] [G loss: 3.284720]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "134 [D loss: 0.075053, acc.: 96.88%] [G loss: 4.331696]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "135 [D loss: 0.050164, acc.: 100.00%] [G loss: 4.518158]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "136 [D loss: 0.164349, acc.: 93.75%] [G loss: 4.416587]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "137 [D loss: 0.199737, acc.: 93.75%] [G loss: 4.839092]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "138 [D loss: 0.064476, acc.: 100.00%] [G loss: 4.387179]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "139 [D loss: 0.198059, acc.: 87.50%] [G loss: 5.291814]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "140 [D loss: 0.660569, acc.: 78.12%] [G loss: 2.548874]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "141 [D loss: 0.482651, acc.: 78.12%] [G loss: 3.531394]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "142 [D loss: 0.075536, acc.: 100.00%] [G loss: 5.091271]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "143 [D loss: 0.069683, acc.: 96.88%] [G loss: 4.881266]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "144 [D loss: 0.215681, acc.: 93.75%] [G loss: 3.089485]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "145 [D loss: 0.207626, acc.: 93.75%] [G loss: 3.534030]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "146 [D loss: 0.158476, acc.: 93.75%] [G loss: 4.828911]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "147 [D loss: 0.069166, acc.: 96.88%] [G loss: 4.296388]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "148 [D loss: 0.221202, acc.: 93.75%] [G loss: 4.294062]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "149 [D loss: 0.165824, acc.: 93.75%] [G loss: 3.665353]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "150 [D loss: 0.076553, acc.: 96.88%] [G loss: 3.710862]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "151 [D loss: 0.168427, acc.: 90.62%] [G loss: 3.642526]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "152 [D loss: 0.316686, acc.: 84.38%] [G loss: 4.734854]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "153 [D loss: 1.209206, acc.: 56.25%] [G loss: 1.905121]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "154 [D loss: 0.496965, acc.: 71.88%] [G loss: 2.006546]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "155 [D loss: 0.152804, acc.: 87.50%] [G loss: 3.476201]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "156 [D loss: 0.086418, acc.: 100.00%] [G loss: 4.041049]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "157 [D loss: 0.089435, acc.: 96.88%] [G loss: 3.312983]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "158 [D loss: 0.109363, acc.: 96.88%] [G loss: 3.192946]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "159 [D loss: 0.134857, acc.: 96.88%] [G loss: 3.237183]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "160 [D loss: 0.107102, acc.: 96.88%] [G loss: 3.187390]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "161 [D loss: 0.078117, acc.: 96.88%] [G loss: 3.067873]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "162 [D loss: 0.188570, acc.: 90.62%] [G loss: 3.044487]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "163 [D loss: 0.352434, acc.: 87.50%] [G loss: 1.949946]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "164 [D loss: 0.274914, acc.: 87.50%] [G loss: 3.595517]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "165 [D loss: 0.109469, acc.: 100.00%] [G loss: 3.421004]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "166 [D loss: 0.135188, acc.: 96.88%] [G loss: 3.139785]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "167 [D loss: 0.093190, acc.: 100.00%] [G loss: 3.578601]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "168 [D loss: 0.478649, acc.: 81.25%] [G loss: 1.662418]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "169 [D loss: 0.418056, acc.: 78.12%] [G loss: 3.756066]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "170 [D loss: 0.095972, acc.: 100.00%] [G loss: 3.633835]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "171 [D loss: 0.600379, acc.: 75.00%] [G loss: 2.127130]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "172 [D loss: 0.115723, acc.: 93.75%] [G loss: 2.668489]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "173 [D loss: 0.196930, acc.: 93.75%] [G loss: 3.872851]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "174 [D loss: 0.137649, acc.: 93.75%] [G loss: 2.611761]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "175 [D loss: 0.295291, acc.: 84.38%] [G loss: 3.495890]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "176 [D loss: 0.188181, acc.: 96.88%] [G loss: 2.272807]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "177 [D loss: 0.259622, acc.: 90.62%] [G loss: 3.592565]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "178 [D loss: 0.509437, acc.: 68.75%] [G loss: 3.199799]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "179 [D loss: 0.141199, acc.: 96.88%] [G loss: 3.255455]\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "180 [D loss: 0.608335, acc.: 75.00%] [G loss: 2.568152]\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "181 [D loss: 0.144517, acc.: 93.75%] [G loss: 3.643356]\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "182 [D loss: 0.743580, acc.: 56.25%] [G loss: 3.245147]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "183 [D loss: 0.132053, acc.: 100.00%] [G loss: 3.541656]\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "184 [D loss: 0.956051, acc.: 53.12%] [G loss: 1.775004]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "185 [D loss: 0.204677, acc.: 90.62%] [G loss: 3.303719]\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "186 [D loss: 0.346317, acc.: 84.38%] [G loss: 2.474229]\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "187 [D loss: 0.419489, acc.: 81.25%] [G loss: 2.372171]\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "188 [D loss: 0.144341, acc.: 93.75%] [G loss: 2.904643]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "189 [D loss: 0.579206, acc.: 75.00%] [G loss: 1.796115]\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "190 [D loss: 0.257145, acc.: 84.38%] [G loss: 3.048990]\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "191 [D loss: 0.099142, acc.: 100.00%] [G loss: 3.948421]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "192 [D loss: 0.504089, acc.: 78.12%] [G loss: 2.636685]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "193 [D loss: 0.131473, acc.: 93.75%] [G loss: 3.252974]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "194 [D loss: 0.140822, acc.: 93.75%] [G loss: 3.223801]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "195 [D loss: 0.290804, acc.: 90.62%] [G loss: 2.226828]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "196 [D loss: 0.144742, acc.: 96.88%] [G loss: 3.563912]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "197 [D loss: 0.332867, acc.: 84.38%] [G loss: 2.381739]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "198 [D loss: 0.120317, acc.: 96.88%] [G loss: 3.268699]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "199 [D loss: 0.228147, acc.: 90.62%] [G loss: 3.390138]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "200 [D loss: 0.358091, acc.: 81.25%] [G loss: 2.594221]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "201 [D loss: 0.259326, acc.: 87.50%] [G loss: 4.428140]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "202 [D loss: 0.913471, acc.: 46.88%] [G loss: 1.430305]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "203 [D loss: 0.346217, acc.: 75.00%] [G loss: 3.234386]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "204 [D loss: 0.068817, acc.: 100.00%] [G loss: 3.963189]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "205 [D loss: 0.305409, acc.: 84.38%] [G loss: 3.138946]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "206 [D loss: 0.159831, acc.: 96.88%] [G loss: 3.968265]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "207 [D loss: 0.177892, acc.: 96.88%] [G loss: 2.830132]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "208 [D loss: 0.140453, acc.: 100.00%] [G loss: 2.309916]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "209 [D loss: 0.196776, acc.: 93.75%] [G loss: 3.567668]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "210 [D loss: 0.760265, acc.: 50.00%] [G loss: 1.887507]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "211 [D loss: 0.203656, acc.: 93.75%] [G loss: 3.042662]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "212 [D loss: 0.326920, acc.: 84.38%] [G loss: 3.494892]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "213 [D loss: 0.323905, acc.: 84.38%] [G loss: 3.302634]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "214 [D loss: 0.425784, acc.: 81.25%] [G loss: 3.103694]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "215 [D loss: 0.318812, acc.: 87.50%] [G loss: 3.082003]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "216 [D loss: 0.409440, acc.: 75.00%] [G loss: 3.405639]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "217 [D loss: 0.406441, acc.: 78.12%] [G loss: 2.703163]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "218 [D loss: 0.130623, acc.: 96.88%] [G loss: 3.118218]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "219 [D loss: 0.885220, acc.: 56.25%] [G loss: 1.585781]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "220 [D loss: 0.123819, acc.: 96.88%] [G loss: 2.896183]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "221 [D loss: 0.507739, acc.: 75.00%] [G loss: 2.429310]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "222 [D loss: 0.227255, acc.: 84.38%] [G loss: 3.975111]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "223 [D loss: 0.736312, acc.: 56.25%] [G loss: 2.106423]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "224 [D loss: 0.232310, acc.: 84.38%] [G loss: 3.862735]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "225 [D loss: 0.500280, acc.: 75.00%] [G loss: 1.820147]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "226 [D loss: 0.202994, acc.: 93.75%] [G loss: 2.972581]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "227 [D loss: 0.481189, acc.: 75.00%] [G loss: 2.133613]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "228 [D loss: 0.274117, acc.: 93.75%] [G loss: 2.513597]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "229 [D loss: 0.175953, acc.: 96.88%] [G loss: 2.770768]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "230 [D loss: 0.626867, acc.: 68.75%] [G loss: 2.239351]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "231 [D loss: 0.271515, acc.: 90.62%] [G loss: 2.591198]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "232 [D loss: 0.496382, acc.: 71.88%] [G loss: 2.794577]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "233 [D loss: 0.274331, acc.: 90.62%] [G loss: 2.183499]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "234 [D loss: 0.456209, acc.: 75.00%] [G loss: 2.176850]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "235 [D loss: 0.253489, acc.: 93.75%] [G loss: 2.822007]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "236 [D loss: 0.436117, acc.: 78.12%] [G loss: 2.710113]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "237 [D loss: 0.277462, acc.: 90.62%] [G loss: 3.378417]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "238 [D loss: 0.725563, acc.: 50.00%] [G loss: 1.952768]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "239 [D loss: 0.354803, acc.: 87.50%] [G loss: 3.879980]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "240 [D loss: 1.450034, acc.: 34.38%] [G loss: 0.698310]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "241 [D loss: 0.671381, acc.: 59.38%] [G loss: 2.248006]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "242 [D loss: 0.299217, acc.: 96.88%] [G loss: 2.766684]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "243 [D loss: 0.759492, acc.: 50.00%] [G loss: 1.303354]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "244 [D loss: 0.290347, acc.: 87.50%] [G loss: 2.120198]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "245 [D loss: 0.576951, acc.: 65.62%] [G loss: 1.453805]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "246 [D loss: 0.361782, acc.: 78.12%] [G loss: 2.392422]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "247 [D loss: 0.307804, acc.: 93.75%] [G loss: 1.788180]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "248 [D loss: 0.552771, acc.: 71.88%] [G loss: 2.089963]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "249 [D loss: 0.222304, acc.: 93.75%] [G loss: 2.238060]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "250 [D loss: 0.750954, acc.: 50.00%] [G loss: 1.549784]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "251 [D loss: 0.282565, acc.: 93.75%] [G loss: 2.406096]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "252 [D loss: 0.803594, acc.: 50.00%] [G loss: 1.818816]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "253 [D loss: 0.284998, acc.: 90.62%] [G loss: 2.802278]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "254 [D loss: 0.477574, acc.: 81.25%] [G loss: 1.579592]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "255 [D loss: 0.609031, acc.: 59.38%] [G loss: 1.282482]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "256 [D loss: 0.340935, acc.: 81.25%] [G loss: 2.620959]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "257 [D loss: 0.611571, acc.: 65.62%] [G loss: 1.324734]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "258 [D loss: 0.375980, acc.: 75.00%] [G loss: 2.397480]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "259 [D loss: 0.809431, acc.: 50.00%] [G loss: 1.027679]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "260 [D loss: 0.359504, acc.: 81.25%] [G loss: 2.631543]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "261 [D loss: 0.958792, acc.: 37.50%] [G loss: 1.040077]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "262 [D loss: 0.415445, acc.: 84.38%] [G loss: 2.109279]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "263 [D loss: 0.573214, acc.: 65.62%] [G loss: 1.663988]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "264 [D loss: 0.707874, acc.: 53.12%] [G loss: 1.199480]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "265 [D loss: 0.396137, acc.: 81.25%] [G loss: 2.132206]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "266 [D loss: 1.182573, acc.: 21.88%] [G loss: 0.799713]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "267 [D loss: 0.569384, acc.: 59.38%] [G loss: 1.524681]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "268 [D loss: 0.824576, acc.: 46.88%] [G loss: 1.510150]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "269 [D loss: 0.677830, acc.: 56.25%] [G loss: 1.249225]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "270 [D loss: 0.618469, acc.: 68.75%] [G loss: 1.747930]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "271 [D loss: 0.736285, acc.: 59.38%] [G loss: 1.307038]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "272 [D loss: 0.757898, acc.: 53.12%] [G loss: 1.277102]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "273 [D loss: 0.491467, acc.: 75.00%] [G loss: 1.599970]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "274 [D loss: 0.733393, acc.: 46.88%] [G loss: 1.119512]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "275 [D loss: 0.565574, acc.: 62.50%] [G loss: 1.550615]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "276 [D loss: 0.708927, acc.: 53.12%] [G loss: 0.944668]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "277 [D loss: 0.791245, acc.: 40.62%] [G loss: 1.072098]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "278 [D loss: 0.687355, acc.: 53.12%] [G loss: 1.228204]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "279 [D loss: 0.993056, acc.: 18.75%] [G loss: 0.678044]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "280 [D loss: 0.738714, acc.: 40.62%] [G loss: 1.004075]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "281 [D loss: 0.750981, acc.: 50.00%] [G loss: 1.191590]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "282 [D loss: 0.754510, acc.: 40.62%] [G loss: 0.985231]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "283 [D loss: 0.686846, acc.: 59.38%] [G loss: 0.913569]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "284 [D loss: 0.838350, acc.: 31.25%] [G loss: 0.793805]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "285 [D loss: 0.680140, acc.: 56.25%] [G loss: 0.942663]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "286 [D loss: 0.809511, acc.: 31.25%] [G loss: 0.848286]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "287 [D loss: 0.592558, acc.: 62.50%] [G loss: 1.052824]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "288 [D loss: 0.790988, acc.: 28.12%] [G loss: 0.826335]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "289 [D loss: 0.783515, acc.: 37.50%] [G loss: 0.801996]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "290 [D loss: 0.752106, acc.: 50.00%] [G loss: 0.926045]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "291 [D loss: 0.743754, acc.: 37.50%] [G loss: 0.884284]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "292 [D loss: 0.604404, acc.: 62.50%] [G loss: 1.087752]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "293 [D loss: 0.877243, acc.: 28.12%] [G loss: 0.714140]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "294 [D loss: 0.646564, acc.: 43.75%] [G loss: 0.892181]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "295 [D loss: 0.753357, acc.: 43.75%] [G loss: 0.888025]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "296 [D loss: 0.752838, acc.: 43.75%] [G loss: 0.906243]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "297 [D loss: 0.713166, acc.: 40.62%] [G loss: 0.835230]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "298 [D loss: 0.668866, acc.: 50.00%] [G loss: 0.907404]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "299 [D loss: 0.612075, acc.: 56.25%] [G loss: 1.089098]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "300 [D loss: 0.754368, acc.: 46.88%] [G loss: 0.872769]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "301 [D loss: 0.661431, acc.: 56.25%] [G loss: 0.897774]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "302 [D loss: 0.762084, acc.: 40.62%] [G loss: 0.817697]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "303 [D loss: 0.696124, acc.: 50.00%] [G loss: 0.881581]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "304 [D loss: 0.685022, acc.: 59.38%] [G loss: 0.815081]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "305 [D loss: 0.822795, acc.: 34.38%] [G loss: 0.723753]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "306 [D loss: 0.661254, acc.: 53.12%] [G loss: 0.740382]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "307 [D loss: 0.690748, acc.: 53.12%] [G loss: 0.867845]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "308 [D loss: 0.625950, acc.: 68.75%] [G loss: 0.890882]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "309 [D loss: 0.738902, acc.: 43.75%] [G loss: 0.805079]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "310 [D loss: 0.684560, acc.: 46.88%] [G loss: 0.719876]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "311 [D loss: 0.801849, acc.: 37.50%] [G loss: 0.639928]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "312 [D loss: 0.638382, acc.: 65.62%] [G loss: 0.785720]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "313 [D loss: 0.732597, acc.: 40.62%] [G loss: 0.808127]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "314 [D loss: 0.728777, acc.: 43.75%] [G loss: 0.727744]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "315 [D loss: 0.658045, acc.: 53.12%] [G loss: 0.849230]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "316 [D loss: 0.649545, acc.: 46.88%] [G loss: 0.821134]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "317 [D loss: 0.744124, acc.: 43.75%] [G loss: 0.773058]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "318 [D loss: 0.735902, acc.: 46.88%] [G loss: 0.723889]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "319 [D loss: 0.750268, acc.: 40.62%] [G loss: 0.681208]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "320 [D loss: 0.699574, acc.: 46.88%] [G loss: 0.698047]\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "321 [D loss: 0.695061, acc.: 46.88%] [G loss: 0.756317]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "322 [D loss: 0.652066, acc.: 46.88%] [G loss: 0.767411]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "323 [D loss: 0.729384, acc.: 50.00%] [G loss: 0.683715]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "324 [D loss: 0.647648, acc.: 59.38%] [G loss: 0.819506]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "325 [D loss: 0.738645, acc.: 43.75%] [G loss: 0.749144]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "326 [D loss: 0.718925, acc.: 46.88%] [G loss: 0.738008]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "327 [D loss: 0.678673, acc.: 46.88%] [G loss: 0.735891]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "328 [D loss: 0.760825, acc.: 34.38%] [G loss: 0.701778]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "329 [D loss: 0.746823, acc.: 50.00%] [G loss: 0.648682]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "330 [D loss: 0.660357, acc.: 50.00%] [G loss: 0.743832]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "331 [D loss: 0.758188, acc.: 37.50%] [G loss: 0.675927]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "332 [D loss: 0.743749, acc.: 37.50%] [G loss: 0.642474]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "333 [D loss: 0.690252, acc.: 43.75%] [G loss: 0.665895]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "334 [D loss: 0.744644, acc.: 40.62%] [G loss: 0.657733]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "335 [D loss: 0.713935, acc.: 43.75%] [G loss: 0.697646]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "336 [D loss: 0.707224, acc.: 46.88%] [G loss: 0.695284]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "337 [D loss: 0.724681, acc.: 34.38%] [G loss: 0.656505]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "338 [D loss: 0.705431, acc.: 37.50%] [G loss: 0.685617]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "339 [D loss: 0.712156, acc.: 43.75%] [G loss: 0.695853]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "340 [D loss: 0.656058, acc.: 50.00%] [G loss: 0.709605]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "341 [D loss: 0.690372, acc.: 43.75%] [G loss: 0.683907]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "342 [D loss: 0.728325, acc.: 50.00%] [G loss: 0.676752]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "343 [D loss: 0.742323, acc.: 40.62%] [G loss: 0.665395]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "344 [D loss: 0.687529, acc.: 53.12%] [G loss: 0.696717]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "345 [D loss: 0.629755, acc.: 56.25%] [G loss: 0.773173]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "346 [D loss: 0.703336, acc.: 37.50%] [G loss: 0.725508]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "347 [D loss: 0.698580, acc.: 46.88%] [G loss: 0.676821]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "348 [D loss: 0.731015, acc.: 43.75%] [G loss: 0.634461]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "349 [D loss: 0.727087, acc.: 46.88%] [G loss: 0.664127]\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "350 [D loss: 0.693065, acc.: 46.88%] [G loss: 0.674365]\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "351 [D loss: 0.696438, acc.: 46.88%] [G loss: 0.683876]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "352 [D loss: 0.681368, acc.: 46.88%] [G loss: 0.716838]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "353 [D loss: 0.693725, acc.: 50.00%] [G loss: 0.668886]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "354 [D loss: 0.710329, acc.: 50.00%] [G loss: 0.686575]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "355 [D loss: 0.656234, acc.: 56.25%] [G loss: 0.714301]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "356 [D loss: 0.719420, acc.: 40.62%] [G loss: 0.669278]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "357 [D loss: 0.723291, acc.: 50.00%] [G loss: 0.661801]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "358 [D loss: 0.684027, acc.: 37.50%] [G loss: 0.670825]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "359 [D loss: 0.681632, acc.: 50.00%] [G loss: 0.666681]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "360 [D loss: 0.688900, acc.: 46.88%] [G loss: 0.666104]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "361 [D loss: 0.632001, acc.: 50.00%] [G loss: 0.710414]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "362 [D loss: 0.705588, acc.: 46.88%] [G loss: 0.701895]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "363 [D loss: 0.712511, acc.: 46.88%] [G loss: 0.679593]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "364 [D loss: 0.665911, acc.: 56.25%] [G loss: 0.691515]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "365 [D loss: 0.706629, acc.: 56.25%] [G loss: 0.652193]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "366 [D loss: 0.683368, acc.: 46.88%] [G loss: 0.667796]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "367 [D loss: 0.686838, acc.: 59.38%] [G loss: 0.665766]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "368 [D loss: 0.709417, acc.: 46.88%] [G loss: 0.686856]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "369 [D loss: 0.709921, acc.: 40.62%] [G loss: 0.651889]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "370 [D loss: 0.656555, acc.: 50.00%] [G loss: 0.679635]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "371 [D loss: 0.683895, acc.: 43.75%] [G loss: 0.681894]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "372 [D loss: 0.712649, acc.: 37.50%] [G loss: 0.686120]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "373 [D loss: 0.634091, acc.: 59.38%] [G loss: 0.689763]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "374 [D loss: 0.693871, acc.: 53.12%] [G loss: 0.683604]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "375 [D loss: 0.674843, acc.: 53.12%] [G loss: 0.667971]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "376 [D loss: 0.669315, acc.: 53.12%] [G loss: 0.665474]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "377 [D loss: 0.716598, acc.: 40.62%] [G loss: 0.679870]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "378 [D loss: 0.719431, acc.: 43.75%] [G loss: 0.645761]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "379 [D loss: 0.662633, acc.: 43.75%] [G loss: 0.704686]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "380 [D loss: 0.667835, acc.: 56.25%] [G loss: 0.695578]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "381 [D loss: 0.673979, acc.: 53.12%] [G loss: 0.676475]\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "382 [D loss: 0.683292, acc.: 43.75%] [G loss: 0.659942]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "383 [D loss: 0.669752, acc.: 56.25%] [G loss: 0.681304]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "384 [D loss: 0.701719, acc.: 46.88%] [G loss: 0.675377]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "385 [D loss: 0.667816, acc.: 50.00%] [G loss: 0.665785]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "386 [D loss: 0.663216, acc.: 50.00%] [G loss: 0.702333]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "387 [D loss: 0.701544, acc.: 43.75%] [G loss: 0.686302]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "388 [D loss: 0.683636, acc.: 53.12%] [G loss: 0.664750]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "389 [D loss: 0.680094, acc.: 50.00%] [G loss: 0.658102]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "390 [D loss: 0.682578, acc.: 43.75%] [G loss: 0.656832]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "391 [D loss: 0.687001, acc.: 53.12%] [G loss: 0.659446]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "392 [D loss: 0.697248, acc.: 43.75%] [G loss: 0.656646]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "393 [D loss: 0.682375, acc.: 50.00%] [G loss: 0.652719]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "394 [D loss: 0.695369, acc.: 46.88%] [G loss: 0.652536]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "395 [D loss: 0.691214, acc.: 50.00%] [G loss: 0.649676]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "396 [D loss: 0.694510, acc.: 56.25%] [G loss: 0.657602]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "397 [D loss: 0.686262, acc.: 46.88%] [G loss: 0.669316]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "398 [D loss: 0.679244, acc.: 53.12%] [G loss: 0.701707]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "399 [D loss: 0.694728, acc.: 50.00%] [G loss: 0.689592]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "400 [D loss: 0.694315, acc.: 46.88%] [G loss: 0.677040]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "401 [D loss: 0.718600, acc.: 40.62%] [G loss: 0.640063]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "402 [D loss: 0.663068, acc.: 50.00%] [G loss: 0.658196]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "403 [D loss: 0.646677, acc.: 59.38%] [G loss: 0.663052]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "404 [D loss: 0.656755, acc.: 59.38%] [G loss: 0.688431]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "405 [D loss: 0.633359, acc.: 62.50%] [G loss: 0.722219]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "406 [D loss: 0.650393, acc.: 53.12%] [G loss: 0.738803]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "407 [D loss: 0.621149, acc.: 62.50%] [G loss: 0.736224]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "408 [D loss: 0.666048, acc.: 53.12%] [G loss: 0.758572]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "409 [D loss: 0.650508, acc.: 65.62%] [G loss: 0.727989]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "410 [D loss: 0.595651, acc.: 65.62%] [G loss: 0.774959]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "411 [D loss: 0.724567, acc.: 46.88%] [G loss: 0.724159]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "412 [D loss: 0.667609, acc.: 46.88%] [G loss: 0.705398]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "413 [D loss: 0.710724, acc.: 37.50%] [G loss: 0.661722]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "414 [D loss: 0.681598, acc.: 53.12%] [G loss: 0.648937]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "415 [D loss: 0.702732, acc.: 43.75%] [G loss: 0.636914]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "416 [D loss: 0.681194, acc.: 43.75%] [G loss: 0.640601]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "417 [D loss: 0.660645, acc.: 53.12%] [G loss: 0.645137]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "418 [D loss: 0.659334, acc.: 56.25%] [G loss: 0.668530]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "419 [D loss: 0.688575, acc.: 50.00%] [G loss: 0.664129]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "420 [D loss: 0.636717, acc.: 53.12%] [G loss: 0.690656]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "421 [D loss: 0.646579, acc.: 53.12%] [G loss: 0.688727]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "422 [D loss: 0.666308, acc.: 43.75%] [G loss: 0.697352]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "423 [D loss: 0.695243, acc.: 40.62%] [G loss: 0.706707]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "424 [D loss: 0.665097, acc.: 43.75%] [G loss: 0.682237]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "425 [D loss: 0.662290, acc.: 50.00%] [G loss: 0.674253]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "426 [D loss: 0.671636, acc.: 46.88%] [G loss: 0.650081]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "427 [D loss: 0.680220, acc.: 43.75%] [G loss: 0.665974]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "428 [D loss: 0.695174, acc.: 40.62%] [G loss: 0.678565]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "429 [D loss: 0.664259, acc.: 50.00%] [G loss: 0.663399]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "430 [D loss: 0.663014, acc.: 46.88%] [G loss: 0.671268]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "431 [D loss: 0.651472, acc.: 50.00%] [G loss: 0.706595]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "432 [D loss: 0.664035, acc.: 43.75%] [G loss: 0.687563]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "433 [D loss: 0.664111, acc.: 56.25%] [G loss: 0.665506]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "434 [D loss: 0.722873, acc.: 34.38%] [G loss: 0.648802]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "435 [D loss: 0.636302, acc.: 50.00%] [G loss: 0.670410]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "436 [D loss: 0.676219, acc.: 50.00%] [G loss: 0.664760]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "437 [D loss: 0.679463, acc.: 43.75%] [G loss: 0.680472]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "438 [D loss: 0.678911, acc.: 46.88%] [G loss: 0.658944]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "439 [D loss: 0.673142, acc.: 46.88%] [G loss: 0.660771]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "440 [D loss: 0.677950, acc.: 46.88%] [G loss: 0.654595]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "441 [D loss: 0.680462, acc.: 43.75%] [G loss: 0.658883]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "442 [D loss: 0.675807, acc.: 43.75%] [G loss: 0.653510]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "443 [D loss: 0.655850, acc.: 53.12%] [G loss: 0.664468]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "444 [D loss: 0.669421, acc.: 53.12%] [G loss: 0.660898]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "445 [D loss: 0.660419, acc.: 59.38%] [G loss: 0.647533]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "446 [D loss: 0.657148, acc.: 50.00%] [G loss: 0.670151]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "447 [D loss: 0.666819, acc.: 53.12%] [G loss: 0.680438]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "448 [D loss: 0.673243, acc.: 43.75%] [G loss: 0.681735]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "449 [D loss: 0.675606, acc.: 46.88%] [G loss: 0.696650]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "450 [D loss: 0.668355, acc.: 53.12%] [G loss: 0.686905]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "451 [D loss: 0.694834, acc.: 50.00%] [G loss: 0.671557]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "452 [D loss: 0.650143, acc.: 53.12%] [G loss: 0.668640]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "453 [D loss: 0.656009, acc.: 56.25%] [G loss: 0.664302]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "454 [D loss: 0.679814, acc.: 53.12%] [G loss: 0.665650]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "455 [D loss: 0.652228, acc.: 53.12%] [G loss: 0.673197]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "456 [D loss: 0.681787, acc.: 50.00%] [G loss: 0.664888]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "457 [D loss: 0.670761, acc.: 50.00%] [G loss: 0.674903]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "458 [D loss: 0.684519, acc.: 43.75%] [G loss: 0.662779]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "459 [D loss: 0.668829, acc.: 50.00%] [G loss: 0.677211]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "460 [D loss: 0.672475, acc.: 53.12%] [G loss: 0.667961]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "461 [D loss: 0.654359, acc.: 46.88%] [G loss: 0.680233]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "462 [D loss: 0.693376, acc.: 50.00%] [G loss: 0.705813]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "463 [D loss: 0.643872, acc.: 56.25%] [G loss: 0.715921]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "464 [D loss: 0.651288, acc.: 50.00%] [G loss: 0.722394]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "465 [D loss: 0.655330, acc.: 56.25%] [G loss: 0.712437]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "466 [D loss: 0.668659, acc.: 46.88%] [G loss: 0.708954]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "467 [D loss: 0.695682, acc.: 50.00%] [G loss: 0.718083]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "468 [D loss: 0.672982, acc.: 46.88%] [G loss: 0.700183]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "469 [D loss: 0.655728, acc.: 53.12%] [G loss: 0.700799]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "470 [D loss: 0.665832, acc.: 53.12%] [G loss: 0.696781]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "471 [D loss: 0.676832, acc.: 50.00%] [G loss: 0.673969]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "472 [D loss: 0.675576, acc.: 50.00%] [G loss: 0.673210]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "473 [D loss: 0.658600, acc.: 56.25%] [G loss: 0.680344]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "474 [D loss: 0.658792, acc.: 50.00%] [G loss: 0.674693]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "475 [D loss: 0.657887, acc.: 53.12%] [G loss: 0.678219]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "476 [D loss: 0.665817, acc.: 46.88%] [G loss: 0.681260]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "477 [D loss: 0.675366, acc.: 56.25%] [G loss: 0.694725]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "478 [D loss: 0.637155, acc.: 62.50%] [G loss: 0.698879]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "479 [D loss: 0.655673, acc.: 62.50%] [G loss: 0.681758]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "480 [D loss: 0.692647, acc.: 50.00%] [G loss: 0.686453]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "481 [D loss: 0.677827, acc.: 59.38%] [G loss: 0.685741]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "482 [D loss: 0.630489, acc.: 68.75%] [G loss: 0.697642]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "483 [D loss: 0.690542, acc.: 50.00%] [G loss: 0.702642]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "484 [D loss: 0.621169, acc.: 56.25%] [G loss: 0.701279]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "485 [D loss: 0.664529, acc.: 59.38%] [G loss: 0.694380]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "486 [D loss: 0.678422, acc.: 56.25%] [G loss: 0.664927]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "487 [D loss: 0.643605, acc.: 65.62%] [G loss: 0.663260]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "488 [D loss: 0.654973, acc.: 65.62%] [G loss: 0.670629]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "489 [D loss: 0.646734, acc.: 53.12%] [G loss: 0.669621]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "490 [D loss: 0.673192, acc.: 50.00%] [G loss: 0.687727]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "491 [D loss: 0.678437, acc.: 59.38%] [G loss: 0.695416]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "492 [D loss: 0.673191, acc.: 40.62%] [G loss: 0.699425]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "493 [D loss: 0.683391, acc.: 46.88%] [G loss: 0.696994]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "494 [D loss: 0.667511, acc.: 56.25%] [G loss: 0.701984]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "495 [D loss: 0.663986, acc.: 46.88%] [G loss: 0.699969]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "496 [D loss: 0.661693, acc.: 46.88%] [G loss: 0.693130]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "497 [D loss: 0.637801, acc.: 65.62%] [G loss: 0.700006]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "498 [D loss: 0.649670, acc.: 56.25%] [G loss: 0.701818]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "499 [D loss: 0.657282, acc.: 56.25%] [G loss: 0.690089]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "500 [D loss: 0.668648, acc.: 53.12%] [G loss: 0.687626]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "501 [D loss: 0.661276, acc.: 56.25%] [G loss: 0.693121]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "502 [D loss: 0.674921, acc.: 53.12%] [G loss: 0.676393]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "503 [D loss: 0.659143, acc.: 56.25%] [G loss: 0.679634]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "504 [D loss: 0.660721, acc.: 50.00%] [G loss: 0.684695]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "505 [D loss: 0.643986, acc.: 50.00%] [G loss: 0.692516]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "506 [D loss: 0.669283, acc.: 56.25%] [G loss: 0.693611]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "507 [D loss: 0.642979, acc.: 59.38%] [G loss: 0.700827]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "508 [D loss: 0.658056, acc.: 46.88%] [G loss: 0.687399]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "509 [D loss: 0.663054, acc.: 46.88%] [G loss: 0.659908]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "510 [D loss: 0.669420, acc.: 46.88%] [G loss: 0.649775]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "511 [D loss: 0.669226, acc.: 50.00%] [G loss: 0.627704]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "512 [D loss: 0.654668, acc.: 53.12%] [G loss: 0.652361]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "513 [D loss: 0.647373, acc.: 53.12%] [G loss: 0.662954]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "514 [D loss: 0.664286, acc.: 53.12%] [G loss: 0.664223]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "515 [D loss: 0.659928, acc.: 50.00%] [G loss: 0.655544]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "516 [D loss: 0.673437, acc.: 50.00%] [G loss: 0.665136]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "517 [D loss: 0.639649, acc.: 56.25%] [G loss: 0.682339]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "518 [D loss: 0.676651, acc.: 53.12%] [G loss: 0.703633]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "519 [D loss: 0.669442, acc.: 53.12%] [G loss: 0.687951]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "520 [D loss: 0.623405, acc.: 65.62%] [G loss: 0.703783]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "521 [D loss: 0.626844, acc.: 68.75%] [G loss: 0.681740]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "522 [D loss: 0.670670, acc.: 46.88%] [G loss: 0.660264]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "523 [D loss: 0.668933, acc.: 59.38%] [G loss: 0.663734]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "524 [D loss: 0.690380, acc.: 46.88%] [G loss: 0.680186]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "525 [D loss: 0.658090, acc.: 53.12%] [G loss: 0.682135]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "526 [D loss: 0.650724, acc.: 56.25%] [G loss: 0.699686]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "527 [D loss: 0.605169, acc.: 71.88%] [G loss: 0.683100]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "528 [D loss: 0.697618, acc.: 56.25%] [G loss: 0.684618]\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "529 [D loss: 0.660633, acc.: 59.38%] [G loss: 0.715167]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "530 [D loss: 0.635632, acc.: 53.12%] [G loss: 0.735934]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "531 [D loss: 0.668838, acc.: 59.38%] [G loss: 0.676369]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "532 [D loss: 0.636509, acc.: 56.25%] [G loss: 0.677601]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "533 [D loss: 0.681370, acc.: 53.12%] [G loss: 0.687237]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "534 [D loss: 0.653820, acc.: 46.88%] [G loss: 0.674789]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "535 [D loss: 0.648037, acc.: 59.38%] [G loss: 0.675517]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "536 [D loss: 0.666935, acc.: 46.88%] [G loss: 0.664368]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "537 [D loss: 0.663123, acc.: 53.12%] [G loss: 0.666940]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "538 [D loss: 0.677201, acc.: 43.75%] [G loss: 0.704533]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "539 [D loss: 0.670392, acc.: 53.12%] [G loss: 0.723420]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "540 [D loss: 0.647765, acc.: 68.75%] [G loss: 0.705530]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "541 [D loss: 0.692241, acc.: 59.38%] [G loss: 0.710079]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "542 [D loss: 0.635424, acc.: 71.88%] [G loss: 0.731950]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "543 [D loss: 0.664489, acc.: 53.12%] [G loss: 0.715326]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "544 [D loss: 0.664061, acc.: 59.38%] [G loss: 0.712403]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "545 [D loss: 0.652361, acc.: 65.62%] [G loss: 0.714938]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "546 [D loss: 0.656965, acc.: 62.50%] [G loss: 0.715010]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "547 [D loss: 0.662917, acc.: 56.25%] [G loss: 0.713626]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "548 [D loss: 0.664549, acc.: 56.25%] [G loss: 0.726916]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "549 [D loss: 0.631608, acc.: 62.50%] [G loss: 0.730580]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "550 [D loss: 0.663610, acc.: 50.00%] [G loss: 0.722649]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "551 [D loss: 0.633978, acc.: 59.38%] [G loss: 0.742826]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "552 [D loss: 0.680263, acc.: 46.88%] [G loss: 0.746744]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "553 [D loss: 0.635865, acc.: 59.38%] [G loss: 0.755631]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "554 [D loss: 0.670705, acc.: 59.38%] [G loss: 0.745901]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "555 [D loss: 0.629674, acc.: 56.25%] [G loss: 0.745750]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "556 [D loss: 0.627474, acc.: 62.50%] [G loss: 0.739342]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "557 [D loss: 0.608159, acc.: 62.50%] [G loss: 0.728735]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "558 [D loss: 0.632819, acc.: 62.50%] [G loss: 0.749386]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "559 [D loss: 0.639763, acc.: 56.25%] [G loss: 0.764766]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "560 [D loss: 0.649348, acc.: 71.88%] [G loss: 0.744547]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "561 [D loss: 0.580433, acc.: 84.38%] [G loss: 0.752397]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "562 [D loss: 0.620514, acc.: 68.75%] [G loss: 0.760044]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "563 [D loss: 0.636477, acc.: 68.75%] [G loss: 0.749607]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "564 [D loss: 0.643203, acc.: 56.25%] [G loss: 0.722670]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "565 [D loss: 0.631371, acc.: 59.38%] [G loss: 0.713301]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "566 [D loss: 0.608093, acc.: 59.38%] [G loss: 0.726522]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "567 [D loss: 0.635957, acc.: 62.50%] [G loss: 0.734123]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "568 [D loss: 0.621013, acc.: 59.38%] [G loss: 0.716779]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "569 [D loss: 0.652084, acc.: 59.38%] [G loss: 0.692416]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "570 [D loss: 0.631722, acc.: 59.38%] [G loss: 0.707061]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "571 [D loss: 0.615165, acc.: 65.62%] [G loss: 0.737421]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "572 [D loss: 0.622526, acc.: 65.62%] [G loss: 0.729271]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "573 [D loss: 0.629994, acc.: 53.12%] [G loss: 0.718037]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "574 [D loss: 0.629622, acc.: 62.50%] [G loss: 0.719861]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "575 [D loss: 0.624899, acc.: 65.62%] [G loss: 0.718983]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "576 [D loss: 0.633427, acc.: 65.62%] [G loss: 0.714913]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "577 [D loss: 0.617460, acc.: 65.62%] [G loss: 0.734142]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "578 [D loss: 0.694326, acc.: 53.12%] [G loss: 0.746596]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "579 [D loss: 0.644571, acc.: 53.12%] [G loss: 0.770386]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "580 [D loss: 0.619078, acc.: 75.00%] [G loss: 0.757415]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "581 [D loss: 0.630033, acc.: 68.75%] [G loss: 0.778825]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "582 [D loss: 0.650437, acc.: 65.62%] [G loss: 0.750019]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "583 [D loss: 0.628284, acc.: 62.50%] [G loss: 0.743773]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "584 [D loss: 0.613708, acc.: 68.75%] [G loss: 0.733299]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "585 [D loss: 0.602674, acc.: 62.50%] [G loss: 0.765925]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "586 [D loss: 0.626515, acc.: 56.25%] [G loss: 0.764160]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "587 [D loss: 0.657074, acc.: 56.25%] [G loss: 0.736889]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "588 [D loss: 0.607687, acc.: 68.75%] [G loss: 0.737268]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "589 [D loss: 0.660989, acc.: 59.38%] [G loss: 0.732421]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "590 [D loss: 0.653517, acc.: 56.25%] [G loss: 0.724885]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "591 [D loss: 0.588520, acc.: 75.00%] [G loss: 0.745299]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "592 [D loss: 0.659968, acc.: 56.25%] [G loss: 0.725064]\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "593 [D loss: 0.621362, acc.: 59.38%] [G loss: 0.693515]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "594 [D loss: 0.637525, acc.: 53.12%] [G loss: 0.721794]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "595 [D loss: 0.691715, acc.: 46.88%] [G loss: 0.729571]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "596 [D loss: 0.687768, acc.: 53.12%] [G loss: 0.733639]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "597 [D loss: 0.677526, acc.: 59.38%] [G loss: 0.733112]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "598 [D loss: 0.655347, acc.: 62.50%] [G loss: 0.762138]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "599 [D loss: 0.646743, acc.: 53.12%] [G loss: 0.760881]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "600 [D loss: 0.695177, acc.: 50.00%] [G loss: 0.742084]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "601 [D loss: 0.661420, acc.: 56.25%] [G loss: 0.737352]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "602 [D loss: 0.616860, acc.: 71.88%] [G loss: 0.761661]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "603 [D loss: 0.647817, acc.: 68.75%] [G loss: 0.781990]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "604 [D loss: 0.676258, acc.: 59.38%] [G loss: 0.717550]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "605 [D loss: 0.644775, acc.: 65.62%] [G loss: 0.703787]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "606 [D loss: 0.672759, acc.: 56.25%] [G loss: 0.714607]\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "607 [D loss: 0.640572, acc.: 59.38%] [G loss: 0.700475]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "608 [D loss: 0.660834, acc.: 59.38%] [G loss: 0.705086]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "609 [D loss: 0.676136, acc.: 53.12%] [G loss: 0.732093]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "610 [D loss: 0.626352, acc.: 71.88%] [G loss: 0.745432]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "611 [D loss: 0.728941, acc.: 40.62%] [G loss: 0.755254]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "612 [D loss: 0.679478, acc.: 53.12%] [G loss: 0.761572]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "613 [D loss: 0.651850, acc.: 62.50%] [G loss: 0.764082]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "614 [D loss: 0.642716, acc.: 59.38%] [G loss: 0.767640]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "615 [D loss: 0.620767, acc.: 59.38%] [G loss: 0.755290]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "616 [D loss: 0.645964, acc.: 75.00%] [G loss: 0.746116]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "617 [D loss: 0.658627, acc.: 50.00%] [G loss: 0.739517]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "618 [D loss: 0.624776, acc.: 62.50%] [G loss: 0.774209]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "619 [D loss: 0.644838, acc.: 56.25%] [G loss: 0.813573]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "620 [D loss: 0.643745, acc.: 68.75%] [G loss: 0.815618]\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "621 [D loss: 0.654875, acc.: 65.62%] [G loss: 0.797948]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "622 [D loss: 0.695163, acc.: 43.75%] [G loss: 0.738717]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "623 [D loss: 0.676796, acc.: 50.00%] [G loss: 0.729070]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "624 [D loss: 0.654442, acc.: 46.88%] [G loss: 0.733233]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "625 [D loss: 0.659926, acc.: 50.00%] [G loss: 0.733544]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "626 [D loss: 0.634340, acc.: 65.62%] [G loss: 0.737030]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "627 [D loss: 0.613228, acc.: 62.50%] [G loss: 0.783724]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "628 [D loss: 0.679211, acc.: 53.12%] [G loss: 0.740231]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "629 [D loss: 0.633250, acc.: 56.25%] [G loss: 0.763660]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "630 [D loss: 0.640871, acc.: 62.50%] [G loss: 0.751126]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "631 [D loss: 0.686999, acc.: 53.12%] [G loss: 0.789014]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "632 [D loss: 0.657950, acc.: 65.62%] [G loss: 0.757888]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "633 [D loss: 0.615003, acc.: 65.62%] [G loss: 0.765834]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "634 [D loss: 0.646729, acc.: 53.12%] [G loss: 0.805499]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "635 [D loss: 0.645786, acc.: 59.38%] [G loss: 0.807863]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "636 [D loss: 0.660501, acc.: 56.25%] [G loss: 0.762751]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "637 [D loss: 0.644072, acc.: 56.25%] [G loss: 0.788476]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "638 [D loss: 0.745109, acc.: 37.50%] [G loss: 0.759548]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "639 [D loss: 0.643741, acc.: 56.25%] [G loss: 0.768822]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "640 [D loss: 0.663657, acc.: 62.50%] [G loss: 0.776631]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "641 [D loss: 0.698341, acc.: 43.75%] [G loss: 0.765692]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "642 [D loss: 0.645879, acc.: 62.50%] [G loss: 0.767215]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "643 [D loss: 0.686909, acc.: 50.00%] [G loss: 0.734557]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "644 [D loss: 0.685714, acc.: 43.75%] [G loss: 0.686249]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "645 [D loss: 0.671434, acc.: 43.75%] [G loss: 0.693091]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "646 [D loss: 0.702312, acc.: 50.00%] [G loss: 0.710833]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "647 [D loss: 0.652275, acc.: 62.50%] [G loss: 0.715376]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "648 [D loss: 0.635988, acc.: 62.50%] [G loss: 0.756323]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "649 [D loss: 0.636220, acc.: 62.50%] [G loss: 0.791367]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "650 [D loss: 0.667432, acc.: 59.38%] [G loss: 0.795947]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "651 [D loss: 0.663209, acc.: 59.38%] [G loss: 0.826321]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "652 [D loss: 0.600997, acc.: 75.00%] [G loss: 0.828833]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "653 [D loss: 0.673464, acc.: 50.00%] [G loss: 0.793677]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "654 [D loss: 0.658741, acc.: 53.12%] [G loss: 0.732918]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "655 [D loss: 0.652171, acc.: 53.12%] [G loss: 0.759330]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "656 [D loss: 0.640514, acc.: 53.12%] [G loss: 0.737511]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "657 [D loss: 0.670325, acc.: 50.00%] [G loss: 0.777008]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "658 [D loss: 0.635905, acc.: 65.62%] [G loss: 0.774971]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "659 [D loss: 0.717725, acc.: 40.62%] [G loss: 0.760122]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "660 [D loss: 0.627669, acc.: 65.62%] [G loss: 0.770960]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "661 [D loss: 0.662284, acc.: 59.38%] [G loss: 0.732191]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "662 [D loss: 0.643969, acc.: 50.00%] [G loss: 0.770041]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "663 [D loss: 0.656614, acc.: 56.25%] [G loss: 0.764601]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "664 [D loss: 0.649388, acc.: 62.50%] [G loss: 0.720846]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "665 [D loss: 0.679994, acc.: 46.88%] [G loss: 0.720834]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "666 [D loss: 0.652212, acc.: 68.75%] [G loss: 0.719808]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "667 [D loss: 0.662465, acc.: 53.12%] [G loss: 0.707511]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "668 [D loss: 0.654230, acc.: 53.12%] [G loss: 0.712337]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "669 [D loss: 0.639246, acc.: 65.62%] [G loss: 0.703565]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "670 [D loss: 0.586198, acc.: 78.12%] [G loss: 0.695045]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "671 [D loss: 0.683756, acc.: 53.12%] [G loss: 0.710663]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "672 [D loss: 0.638097, acc.: 68.75%] [G loss: 0.699600]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "673 [D loss: 0.637557, acc.: 56.25%] [G loss: 0.709588]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "674 [D loss: 0.681611, acc.: 53.12%] [G loss: 0.739852]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "675 [D loss: 0.621807, acc.: 71.88%] [G loss: 0.726503]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "676 [D loss: 0.647258, acc.: 56.25%] [G loss: 0.722354]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "677 [D loss: 0.684372, acc.: 53.12%] [G loss: 0.716747]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "678 [D loss: 0.627306, acc.: 65.62%] [G loss: 0.745598]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "679 [D loss: 0.675921, acc.: 53.12%] [G loss: 0.755838]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "680 [D loss: 0.658977, acc.: 62.50%] [G loss: 0.771049]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "681 [D loss: 0.685120, acc.: 50.00%] [G loss: 0.767727]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "682 [D loss: 0.655426, acc.: 56.25%] [G loss: 0.722665]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "683 [D loss: 0.644815, acc.: 59.38%] [G loss: 0.715600]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "684 [D loss: 0.658481, acc.: 59.38%] [G loss: 0.722075]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "685 [D loss: 0.642975, acc.: 62.50%] [G loss: 0.741496]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "686 [D loss: 0.687830, acc.: 43.75%] [G loss: 0.764272]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "687 [D loss: 0.706235, acc.: 37.50%] [G loss: 0.732058]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "688 [D loss: 0.673271, acc.: 53.12%] [G loss: 0.735221]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "689 [D loss: 0.675694, acc.: 62.50%] [G loss: 0.710193]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "690 [D loss: 0.658680, acc.: 59.38%] [G loss: 0.722023]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "691 [D loss: 0.662006, acc.: 40.62%] [G loss: 0.701864]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "692 [D loss: 0.670762, acc.: 56.25%] [G loss: 0.676018]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "693 [D loss: 0.642876, acc.: 62.50%] [G loss: 0.682874]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "694 [D loss: 0.663141, acc.: 50.00%] [G loss: 0.721235]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "695 [D loss: 0.686910, acc.: 46.88%] [G loss: 0.716753]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "696 [D loss: 0.612842, acc.: 75.00%] [G loss: 0.705608]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "697 [D loss: 0.644352, acc.: 59.38%] [G loss: 0.708988]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "698 [D loss: 0.670639, acc.: 56.25%] [G loss: 0.697512]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "699 [D loss: 0.638271, acc.: 65.62%] [G loss: 0.712593]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "700 [D loss: 0.657969, acc.: 56.25%] [G loss: 0.749174]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "701 [D loss: 0.694353, acc.: 56.25%] [G loss: 0.764807]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "702 [D loss: 0.666219, acc.: 53.12%] [G loss: 0.739017]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "703 [D loss: 0.695972, acc.: 46.88%] [G loss: 0.722266]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "704 [D loss: 0.648754, acc.: 59.38%] [G loss: 0.729645]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "705 [D loss: 0.674074, acc.: 50.00%] [G loss: 0.726956]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "706 [D loss: 0.625465, acc.: 65.62%] [G loss: 0.704472]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "707 [D loss: 0.638599, acc.: 56.25%] [G loss: 0.727319]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "708 [D loss: 0.707910, acc.: 50.00%] [G loss: 0.717509]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "709 [D loss: 0.648101, acc.: 53.12%] [G loss: 0.705944]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "710 [D loss: 0.672791, acc.: 53.12%] [G loss: 0.697980]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "711 [D loss: 0.617898, acc.: 71.88%] [G loss: 0.702725]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "712 [D loss: 0.643773, acc.: 59.38%] [G loss: 0.724272]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "713 [D loss: 0.635844, acc.: 59.38%] [G loss: 0.738082]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "714 [D loss: 0.642249, acc.: 65.62%] [G loss: 0.736063]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "715 [D loss: 0.635627, acc.: 59.38%] [G loss: 0.720593]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "716 [D loss: 0.632431, acc.: 68.75%] [G loss: 0.707648]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "717 [D loss: 0.661323, acc.: 56.25%] [G loss: 0.731042]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "718 [D loss: 0.631746, acc.: 68.75%] [G loss: 0.738525]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "719 [D loss: 0.672704, acc.: 50.00%] [G loss: 0.745222]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "720 [D loss: 0.685257, acc.: 50.00%] [G loss: 0.716769]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "721 [D loss: 0.660182, acc.: 53.12%] [G loss: 0.721791]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "722 [D loss: 0.649943, acc.: 62.50%] [G loss: 0.703090]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "723 [D loss: 0.641472, acc.: 50.00%] [G loss: 0.752166]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "724 [D loss: 0.629531, acc.: 68.75%] [G loss: 0.835142]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "725 [D loss: 0.672348, acc.: 46.88%] [G loss: 0.786852]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "726 [D loss: 0.654139, acc.: 56.25%] [G loss: 0.737400]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "727 [D loss: 0.597661, acc.: 62.50%] [G loss: 0.730502]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "728 [D loss: 0.649093, acc.: 59.38%] [G loss: 0.748510]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "729 [D loss: 0.666327, acc.: 56.25%] [G loss: 0.732410]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "730 [D loss: 0.694324, acc.: 46.88%] [G loss: 0.685782]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "731 [D loss: 0.656962, acc.: 53.12%] [G loss: 0.700815]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "732 [D loss: 0.671120, acc.: 59.38%] [G loss: 0.708117]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "733 [D loss: 0.652713, acc.: 62.50%] [G loss: 0.708352]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "734 [D loss: 0.708425, acc.: 50.00%] [G loss: 0.734405]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "735 [D loss: 0.620661, acc.: 78.12%] [G loss: 0.741845]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "736 [D loss: 0.605099, acc.: 68.75%] [G loss: 0.729986]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "737 [D loss: 0.626892, acc.: 65.62%] [G loss: 0.700827]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "738 [D loss: 0.638512, acc.: 65.62%] [G loss: 0.732302]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "739 [D loss: 0.648157, acc.: 71.88%] [G loss: 0.707460]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "740 [D loss: 0.680025, acc.: 62.50%] [G loss: 0.751871]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "741 [D loss: 0.658388, acc.: 59.38%] [G loss: 0.764449]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "742 [D loss: 0.662119, acc.: 62.50%] [G loss: 0.702071]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "743 [D loss: 0.695699, acc.: 43.75%] [G loss: 0.767751]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "744 [D loss: 0.625698, acc.: 71.88%] [G loss: 0.813870]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "745 [D loss: 0.649779, acc.: 65.62%] [G loss: 0.751606]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "746 [D loss: 0.655618, acc.: 59.38%] [G loss: 0.789984]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "747 [D loss: 0.687912, acc.: 43.75%] [G loss: 0.779504]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "748 [D loss: 0.644146, acc.: 65.62%] [G loss: 0.800062]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "749 [D loss: 0.713032, acc.: 59.38%] [G loss: 0.740336]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "750 [D loss: 0.654184, acc.: 59.38%] [G loss: 0.770283]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "751 [D loss: 0.664433, acc.: 59.38%] [G loss: 0.752630]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "752 [D loss: 0.663572, acc.: 65.62%] [G loss: 0.785851]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "753 [D loss: 0.680815, acc.: 59.38%] [G loss: 0.740119]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "754 [D loss: 0.667919, acc.: 40.62%] [G loss: 0.724568]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "755 [D loss: 0.682999, acc.: 53.12%] [G loss: 0.724304]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "756 [D loss: 0.648957, acc.: 56.25%] [G loss: 0.701476]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "757 [D loss: 0.629041, acc.: 65.62%] [G loss: 0.753219]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "758 [D loss: 0.685886, acc.: 59.38%] [G loss: 0.759257]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "759 [D loss: 0.699340, acc.: 40.62%] [G loss: 0.751461]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "760 [D loss: 0.636671, acc.: 65.62%] [G loss: 0.724971]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "761 [D loss: 0.665612, acc.: 59.38%] [G loss: 0.713191]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "762 [D loss: 0.619950, acc.: 68.75%] [G loss: 0.725755]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "763 [D loss: 0.632148, acc.: 56.25%] [G loss: 0.733775]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "764 [D loss: 0.655083, acc.: 65.62%] [G loss: 0.748505]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "765 [D loss: 0.661544, acc.: 62.50%] [G loss: 0.726115]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "766 [D loss: 0.657369, acc.: 62.50%] [G loss: 0.752352]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "767 [D loss: 0.690720, acc.: 53.12%] [G loss: 0.752550]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "768 [D loss: 0.650642, acc.: 56.25%] [G loss: 0.745456]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "769 [D loss: 0.684213, acc.: 56.25%] [G loss: 0.752707]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "770 [D loss: 0.688021, acc.: 56.25%] [G loss: 0.723214]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "771 [D loss: 0.672943, acc.: 46.88%] [G loss: 0.753754]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "772 [D loss: 0.646375, acc.: 62.50%] [G loss: 0.742951]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "773 [D loss: 0.647723, acc.: 59.38%] [G loss: 0.758487]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "774 [D loss: 0.628995, acc.: 68.75%] [G loss: 0.735484]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "775 [D loss: 0.649248, acc.: 59.38%] [G loss: 0.729334]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "776 [D loss: 0.677177, acc.: 56.25%] [G loss: 0.726783]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "777 [D loss: 0.649374, acc.: 65.62%] [G loss: 0.773447]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "778 [D loss: 0.688155, acc.: 53.12%] [G loss: 0.737233]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "779 [D loss: 0.665008, acc.: 59.38%] [G loss: 0.715513]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "780 [D loss: 0.687973, acc.: 56.25%] [G loss: 0.704308]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "781 [D loss: 0.635274, acc.: 78.12%] [G loss: 0.724096]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "782 [D loss: 0.622249, acc.: 68.75%] [G loss: 0.705041]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "783 [D loss: 0.645791, acc.: 62.50%] [G loss: 0.737228]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "784 [D loss: 0.682743, acc.: 68.75%] [G loss: 0.769696]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "785 [D loss: 0.650258, acc.: 65.62%] [G loss: 0.770250]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "786 [D loss: 0.658745, acc.: 62.50%] [G loss: 0.782627]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "787 [D loss: 0.650099, acc.: 62.50%] [G loss: 0.765431]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "788 [D loss: 0.647001, acc.: 53.12%] [G loss: 0.764751]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "789 [D loss: 0.689291, acc.: 50.00%] [G loss: 0.733061]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "790 [D loss: 0.685230, acc.: 40.62%] [G loss: 0.732087]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "791 [D loss: 0.649424, acc.: 71.88%] [G loss: 0.728330]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "792 [D loss: 0.628958, acc.: 65.62%] [G loss: 0.757539]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "793 [D loss: 0.679238, acc.: 56.25%] [G loss: 0.752514]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "794 [D loss: 0.669848, acc.: 56.25%] [G loss: 0.732181]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "795 [D loss: 0.694626, acc.: 43.75%] [G loss: 0.725021]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "796 [D loss: 0.659535, acc.: 50.00%] [G loss: 0.702198]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "797 [D loss: 0.643114, acc.: 59.38%] [G loss: 0.733914]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "798 [D loss: 0.614347, acc.: 78.12%] [G loss: 0.726366]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "799 [D loss: 0.693074, acc.: 50.00%] [G loss: 0.700406]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "800 [D loss: 0.685286, acc.: 50.00%] [G loss: 0.723203]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "801 [D loss: 0.627469, acc.: 59.38%] [G loss: 0.755040]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "802 [D loss: 0.623556, acc.: 65.62%] [G loss: 0.750081]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "803 [D loss: 0.637917, acc.: 62.50%] [G loss: 0.792173]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "804 [D loss: 0.621986, acc.: 81.25%] [G loss: 0.796466]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "805 [D loss: 0.675856, acc.: 56.25%] [G loss: 0.810594]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "806 [D loss: 0.652650, acc.: 59.38%] [G loss: 0.803090]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "807 [D loss: 0.700643, acc.: 43.75%] [G loss: 0.757399]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "808 [D loss: 0.652118, acc.: 56.25%] [G loss: 0.768924]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "809 [D loss: 0.626145, acc.: 68.75%] [G loss: 0.787621]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "810 [D loss: 0.645586, acc.: 59.38%] [G loss: 0.754156]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "811 [D loss: 0.624288, acc.: 65.62%] [G loss: 0.756713]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "812 [D loss: 0.615847, acc.: 75.00%] [G loss: 0.766128]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "813 [D loss: 0.661684, acc.: 65.62%] [G loss: 0.776696]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "814 [D loss: 0.668226, acc.: 46.88%] [G loss: 0.745482]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "815 [D loss: 0.650132, acc.: 71.88%] [G loss: 0.756645]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "816 [D loss: 0.603237, acc.: 62.50%] [G loss: 0.744610]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "817 [D loss: 0.668710, acc.: 59.38%] [G loss: 0.771060]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "818 [D loss: 0.623451, acc.: 71.88%] [G loss: 0.760172]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "819 [D loss: 0.666470, acc.: 56.25%] [G loss: 0.736578]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "820 [D loss: 0.627715, acc.: 62.50%] [G loss: 0.748162]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "821 [D loss: 0.627506, acc.: 68.75%] [G loss: 0.721341]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "822 [D loss: 0.634885, acc.: 56.25%] [G loss: 0.756844]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "823 [D loss: 0.675737, acc.: 62.50%] [G loss: 0.756983]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "824 [D loss: 0.623130, acc.: 68.75%] [G loss: 0.752026]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "825 [D loss: 0.654428, acc.: 68.75%] [G loss: 0.736278]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "826 [D loss: 0.659045, acc.: 56.25%] [G loss: 0.732763]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "827 [D loss: 0.645825, acc.: 65.62%] [G loss: 0.757353]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "828 [D loss: 0.660309, acc.: 59.38%] [G loss: 0.749444]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "829 [D loss: 0.617253, acc.: 71.88%] [G loss: 0.738397]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "830 [D loss: 0.680912, acc.: 50.00%] [G loss: 0.751992]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "831 [D loss: 0.658920, acc.: 59.38%] [G loss: 0.724423]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "832 [D loss: 0.663757, acc.: 53.12%] [G loss: 0.746655]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "833 [D loss: 0.672721, acc.: 62.50%] [G loss: 0.765976]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "834 [D loss: 0.691758, acc.: 46.88%] [G loss: 0.759182]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "835 [D loss: 0.643713, acc.: 56.25%] [G loss: 0.760544]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "836 [D loss: 0.658345, acc.: 65.62%] [G loss: 0.739881]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "837 [D loss: 0.638214, acc.: 59.38%] [G loss: 0.765072]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "838 [D loss: 0.635595, acc.: 65.62%] [G loss: 0.719914]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "839 [D loss: 0.679037, acc.: 59.38%] [G loss: 0.763722]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "840 [D loss: 0.638718, acc.: 56.25%] [G loss: 0.778661]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "841 [D loss: 0.636814, acc.: 62.50%] [G loss: 0.765393]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "842 [D loss: 0.643760, acc.: 71.88%] [G loss: 0.757759]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "843 [D loss: 0.713704, acc.: 37.50%] [G loss: 0.710053]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "844 [D loss: 0.622741, acc.: 59.38%] [G loss: 0.736692]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "845 [D loss: 0.638540, acc.: 68.75%] [G loss: 0.742932]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "846 [D loss: 0.655308, acc.: 62.50%] [G loss: 0.757504]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "847 [D loss: 0.637186, acc.: 65.62%] [G loss: 0.773093]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "848 [D loss: 0.630092, acc.: 65.62%] [G loss: 0.835638]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "849 [D loss: 0.692821, acc.: 56.25%] [G loss: 0.819796]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "850 [D loss: 0.650379, acc.: 62.50%] [G loss: 0.775821]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "851 [D loss: 0.616588, acc.: 71.88%] [G loss: 0.755975]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "852 [D loss: 0.631180, acc.: 71.88%] [G loss: 0.754155]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "853 [D loss: 0.646557, acc.: 62.50%] [G loss: 0.709030]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "854 [D loss: 0.614688, acc.: 65.62%] [G loss: 0.740185]\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "855 [D loss: 0.653446, acc.: 59.38%] [G loss: 0.753087]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "856 [D loss: 0.656463, acc.: 56.25%] [G loss: 0.723022]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "857 [D loss: 0.657573, acc.: 62.50%] [G loss: 0.751997]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "858 [D loss: 0.657586, acc.: 59.38%] [G loss: 0.756846]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "859 [D loss: 0.618477, acc.: 75.00%] [G loss: 0.768314]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "860 [D loss: 0.625250, acc.: 62.50%] [G loss: 0.751811]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "861 [D loss: 0.630331, acc.: 59.38%] [G loss: 0.769300]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "862 [D loss: 0.614752, acc.: 71.88%] [G loss: 0.767097]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "863 [D loss: 0.657820, acc.: 68.75%] [G loss: 0.752854]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "864 [D loss: 0.626889, acc.: 71.88%] [G loss: 0.752486]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "865 [D loss: 0.583887, acc.: 84.38%] [G loss: 0.746042]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "866 [D loss: 0.652216, acc.: 65.62%] [G loss: 0.736525]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "867 [D loss: 0.644449, acc.: 68.75%] [G loss: 0.761406]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "868 [D loss: 0.674387, acc.: 46.88%] [G loss: 0.803551]\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "869 [D loss: 0.594087, acc.: 71.88%] [G loss: 0.753523]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "870 [D loss: 0.638791, acc.: 62.50%] [G loss: 0.761394]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "871 [D loss: 0.631374, acc.: 68.75%] [G loss: 0.778163]\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "872 [D loss: 0.680388, acc.: 56.25%] [G loss: 0.756358]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "873 [D loss: 0.619730, acc.: 68.75%] [G loss: 0.758263]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "874 [D loss: 0.648241, acc.: 65.62%] [G loss: 0.796084]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "875 [D loss: 0.669230, acc.: 59.38%] [G loss: 0.764277]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "876 [D loss: 0.665808, acc.: 53.12%] [G loss: 0.766042]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "877 [D loss: 0.609251, acc.: 71.88%] [G loss: 0.829034]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "878 [D loss: 0.643733, acc.: 71.88%] [G loss: 0.844921]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "879 [D loss: 0.675498, acc.: 56.25%] [G loss: 0.759832]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "880 [D loss: 0.614542, acc.: 75.00%] [G loss: 0.755941]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "881 [D loss: 0.589493, acc.: 65.62%] [G loss: 0.759578]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "882 [D loss: 0.645266, acc.: 59.38%] [G loss: 0.766647]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "883 [D loss: 0.616070, acc.: 62.50%] [G loss: 0.820792]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "884 [D loss: 0.672593, acc.: 65.62%] [G loss: 0.785639]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "885 [D loss: 0.631652, acc.: 71.88%] [G loss: 0.779680]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "886 [D loss: 0.694113, acc.: 56.25%] [G loss: 0.797036]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "887 [D loss: 0.629066, acc.: 65.62%] [G loss: 0.810132]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "888 [D loss: 0.626975, acc.: 56.25%] [G loss: 0.795833]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "889 [D loss: 0.662499, acc.: 59.38%] [G loss: 0.765530]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "890 [D loss: 0.662113, acc.: 62.50%] [G loss: 0.735529]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "891 [D loss: 0.680116, acc.: 65.62%] [G loss: 0.748666]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "892 [D loss: 0.640813, acc.: 56.25%] [G loss: 0.780247]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "893 [D loss: 0.615931, acc.: 68.75%] [G loss: 0.856938]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "894 [D loss: 0.692478, acc.: 50.00%] [G loss: 0.842433]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "895 [D loss: 0.667410, acc.: 50.00%] [G loss: 0.783100]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "896 [D loss: 0.601393, acc.: 65.62%] [G loss: 0.762342]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "897 [D loss: 0.653145, acc.: 62.50%] [G loss: 0.762118]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "898 [D loss: 0.626088, acc.: 65.62%] [G loss: 0.803441]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "899 [D loss: 0.664153, acc.: 65.62%] [G loss: 0.790472]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "900 [D loss: 0.684245, acc.: 62.50%] [G loss: 0.787352]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "901 [D loss: 0.665248, acc.: 59.38%] [G loss: 0.802977]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "902 [D loss: 0.646139, acc.: 68.75%] [G loss: 0.795897]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "903 [D loss: 0.597902, acc.: 84.38%] [G loss: 0.796280]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "904 [D loss: 0.671827, acc.: 59.38%] [G loss: 0.768869]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "905 [D loss: 0.687536, acc.: 56.25%] [G loss: 0.745824]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "906 [D loss: 0.671382, acc.: 62.50%] [G loss: 0.796168]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "907 [D loss: 0.602551, acc.: 75.00%] [G loss: 0.796740]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "908 [D loss: 0.665470, acc.: 56.25%] [G loss: 0.783943]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "909 [D loss: 0.683260, acc.: 50.00%] [G loss: 0.801221]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "910 [D loss: 0.666417, acc.: 56.25%] [G loss: 0.797896]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "911 [D loss: 0.649758, acc.: 65.62%] [G loss: 0.797318]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "912 [D loss: 0.630766, acc.: 65.62%] [G loss: 0.814856]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "913 [D loss: 0.696460, acc.: 50.00%] [G loss: 0.780952]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "914 [D loss: 0.676737, acc.: 40.62%] [G loss: 0.742996]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "915 [D loss: 0.591222, acc.: 71.88%] [G loss: 0.802362]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "916 [D loss: 0.680977, acc.: 56.25%] [G loss: 0.802483]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "917 [D loss: 0.636387, acc.: 56.25%] [G loss: 0.788605]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "918 [D loss: 0.639337, acc.: 71.88%] [G loss: 0.777052]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "919 [D loss: 0.678413, acc.: 59.38%] [G loss: 0.789250]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "920 [D loss: 0.685283, acc.: 59.38%] [G loss: 0.803872]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "921 [D loss: 0.648998, acc.: 68.75%] [G loss: 0.787451]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "922 [D loss: 0.666346, acc.: 62.50%] [G loss: 0.771895]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "923 [D loss: 0.648740, acc.: 68.75%] [G loss: 0.790568]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "924 [D loss: 0.659236, acc.: 71.88%] [G loss: 0.781651]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "925 [D loss: 0.661239, acc.: 53.12%] [G loss: 0.785915]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "926 [D loss: 0.663486, acc.: 56.25%] [G loss: 0.805128]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "927 [D loss: 0.636919, acc.: 71.88%] [G loss: 0.854069]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "928 [D loss: 0.639856, acc.: 71.88%] [G loss: 0.899716]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "929 [D loss: 0.640356, acc.: 62.50%] [G loss: 0.921473]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "930 [D loss: 0.638677, acc.: 62.50%] [G loss: 0.886759]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "931 [D loss: 0.592299, acc.: 87.50%] [G loss: 0.805083]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "932 [D loss: 0.630188, acc.: 68.75%] [G loss: 0.804131]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "933 [D loss: 0.666430, acc.: 50.00%] [G loss: 0.793560]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "934 [D loss: 0.621791, acc.: 65.62%] [G loss: 0.803369]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "935 [D loss: 0.621092, acc.: 65.62%] [G loss: 0.809401]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "936 [D loss: 0.598904, acc.: 71.88%] [G loss: 0.828560]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "937 [D loss: 0.635206, acc.: 56.25%] [G loss: 0.847359]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "938 [D loss: 0.686386, acc.: 62.50%] [G loss: 0.811022]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "939 [D loss: 0.636944, acc.: 75.00%] [G loss: 0.833694]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "940 [D loss: 0.673307, acc.: 56.25%] [G loss: 0.723741]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "941 [D loss: 0.658541, acc.: 56.25%] [G loss: 0.710141]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "942 [D loss: 0.632198, acc.: 62.50%] [G loss: 0.701332]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "943 [D loss: 0.624638, acc.: 59.38%] [G loss: 0.700502]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "944 [D loss: 0.672240, acc.: 68.75%] [G loss: 0.765172]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "945 [D loss: 0.669754, acc.: 50.00%] [G loss: 0.823273]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "946 [D loss: 0.649134, acc.: 62.50%] [G loss: 0.822522]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "947 [D loss: 0.601244, acc.: 75.00%] [G loss: 0.840775]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "948 [D loss: 0.592623, acc.: 75.00%] [G loss: 0.824688]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "949 [D loss: 0.673200, acc.: 62.50%] [G loss: 0.790339]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "950 [D loss: 0.661092, acc.: 65.62%] [G loss: 0.767689]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "951 [D loss: 0.624245, acc.: 65.62%] [G loss: 0.815472]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "952 [D loss: 0.595118, acc.: 65.62%] [G loss: 0.842215]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "953 [D loss: 0.634829, acc.: 59.38%] [G loss: 0.779506]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "954 [D loss: 0.641416, acc.: 65.62%] [G loss: 0.790675]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "955 [D loss: 0.645284, acc.: 59.38%] [G loss: 0.822832]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "956 [D loss: 0.652732, acc.: 46.88%] [G loss: 0.851866]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "957 [D loss: 0.625134, acc.: 62.50%] [G loss: 0.857687]\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "958 [D loss: 0.670202, acc.: 62.50%] [G loss: 0.826957]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "959 [D loss: 0.610681, acc.: 68.75%] [G loss: 0.858545]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "960 [D loss: 0.671293, acc.: 59.38%] [G loss: 0.809766]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "961 [D loss: 0.594974, acc.: 75.00%] [G loss: 0.814747]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "962 [D loss: 0.662541, acc.: 59.38%] [G loss: 0.751597]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "963 [D loss: 0.602172, acc.: 71.88%] [G loss: 0.777453]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "964 [D loss: 0.636434, acc.: 65.62%] [G loss: 0.774278]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "965 [D loss: 0.635883, acc.: 62.50%] [G loss: 0.748574]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "966 [D loss: 0.630190, acc.: 65.62%] [G loss: 0.786982]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "967 [D loss: 0.600548, acc.: 68.75%] [G loss: 0.818889]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "968 [D loss: 0.660044, acc.: 59.38%] [G loss: 0.831709]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "969 [D loss: 0.632800, acc.: 62.50%] [G loss: 0.836701]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "970 [D loss: 0.616986, acc.: 68.75%] [G loss: 0.807683]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "971 [D loss: 0.564612, acc.: 78.12%] [G loss: 0.845079]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "972 [D loss: 0.672550, acc.: 53.12%] [G loss: 0.842143]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "973 [D loss: 0.705323, acc.: 43.75%] [G loss: 0.771261]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "974 [D loss: 0.632976, acc.: 62.50%] [G loss: 0.809566]\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "975 [D loss: 0.707642, acc.: 50.00%] [G loss: 0.736334]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "976 [D loss: 0.632038, acc.: 59.38%] [G loss: 0.778739]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "977 [D loss: 0.672429, acc.: 62.50%] [G loss: 0.754740]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "978 [D loss: 0.624531, acc.: 68.75%] [G loss: 0.760061]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "979 [D loss: 0.612784, acc.: 75.00%] [G loss: 0.760211]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "980 [D loss: 0.654171, acc.: 62.50%] [G loss: 0.762886]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "981 [D loss: 0.642699, acc.: 68.75%] [G loss: 0.774802]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "982 [D loss: 0.641449, acc.: 71.88%] [G loss: 0.790967]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "983 [D loss: 0.598539, acc.: 75.00%] [G loss: 0.795681]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "984 [D loss: 0.626209, acc.: 75.00%] [G loss: 0.816730]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "985 [D loss: 0.636646, acc.: 59.38%] [G loss: 0.807710]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "986 [D loss: 0.639948, acc.: 65.62%] [G loss: 0.844630]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "987 [D loss: 0.656458, acc.: 56.25%] [G loss: 0.788008]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "988 [D loss: 0.661836, acc.: 53.12%] [G loss: 0.818984]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "989 [D loss: 0.657784, acc.: 62.50%] [G loss: 0.770882]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "990 [D loss: 0.610794, acc.: 62.50%] [G loss: 0.799805]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "991 [D loss: 0.663215, acc.: 65.62%] [G loss: 0.836930]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "992 [D loss: 0.619682, acc.: 68.75%] [G loss: 0.807629]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "993 [D loss: 0.647239, acc.: 65.62%] [G loss: 0.798817]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "994 [D loss: 0.597550, acc.: 65.62%] [G loss: 0.807272]\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "995 [D loss: 0.634052, acc.: 56.25%] [G loss: 0.797573]\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "996 [D loss: 0.660256, acc.: 62.50%] [G loss: 0.805582]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "997 [D loss: 0.603926, acc.: 71.88%] [G loss: 0.776933]\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "998 [D loss: 0.676087, acc.: 56.25%] [G loss: 0.781678]\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "999 [D loss: 0.626011, acc.: 71.88%] [G loss: 0.777823]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "epVJV9sQcZaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting using GAN"
      ],
      "metadata": {
        "id": "5x1tIOd2cRVR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "eBHcCapIbY8D",
        "outputId": "7ce3a323-af21-4a61-f205-b384cca064ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from keras.models import load_model\n",
        "from numpy import asarray\n",
        "from matplotlib import pyplot\n",
        "from numpy.random import randn\n",
        "\n",
        "### FOR A SINGLE IMAGE ####\n",
        "\n",
        "# load model\n",
        "model = load_model('/content/drive/MyDrive/generator_model_100K.h5')\n",
        "\n",
        "#To create same image, suppy same vector each time\n",
        "# all 0s\n",
        "#vector = asarray([[0. for _ in range(100)]])  #Vector of all zeros\n",
        "\n",
        "#To create random images each time...\n",
        "vector = randn(100) #Vector of random numbers (creates a column, need to reshape)\n",
        "vector = vector.reshape(1, 100)\n",
        "\n",
        "# generate image\n",
        "X = model.predict(vector)\n",
        "\n",
        "# plot the result\n",
        "pyplot.imshow(X[0, :, :, 0], cmap='gray_r')\n",
        "pyplot.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### FOR MULTI IMAGES ####\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "# create and save a plot of generated images (reversed grayscale)\n",
        "def save_plot(examples, n):\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\t# define subplot\n",
        "\t\tplt.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tplt.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tplt.imshow(examples[i, :, :, 0], cmap='gray_r')\n",
        "\tplt.show()\n",
        " \n",
        "\n",
        "# generate images\n",
        "# Generate 16 images, each image provide a vector of size 100 as input\n",
        "latent_points = generate_latent_points(100, 16) \n",
        "# generate images\n",
        "X = model.predict(latent_points)\n",
        "# plot the result\n",
        "save_plot(X, 4)  #Plot 4x4 grid (Change to 5 if generating 25 images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "1SIRUzs8fexv",
        "outputId": "bb4b07ce-74e7-47d5-c500-2a9005883cd6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}